{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                COMMENT_ID                    AUTHOR  \\\n",
      "44     z13stv3brxe1snv2i225fnvganneudej004            MFkin PRXPHETZ   \n",
      "215    z124g1oy2wfitb3tw23bw1po2ozhurojq04             LaunchPad Mad   \n",
      "201  z13qgpqwlqbgj5jqy04cgnjqruv0gpdaino0k                    css403   \n",
      "186      z133xzqp3ubgyf2ko22osxkrfzvbd5b2y  TheInfectedDoge Gameplay   \n",
      "324    z135zz0xwx2jetyt523mejn40qifw5hjo04          Jennifer Isaksen   \n",
      "\n",
      "                    DATE                                            CONTENT  \\\n",
      "44   2014-01-20T09:08:39  if you like raw talent, raw lyrics, straight r...   \n",
      "215  2014-11-07T18:11:56  Hello! I'm kind of new to Youtube, And soon i'...   \n",
      "201  2014-11-07T14:25:48                      i am 2,126,492,636 viewer :D﻿   \n",
      "186  2014-11-07T05:04:28                    most viewed video in the world﻿   \n",
      "324  2014-11-12T15:12:47  Hahah, juyk! I allways laugh at the part 1:57....   \n",
      "\n",
      "     CLASS  \n",
      "44       1  \n",
      "215      1  \n",
      "201      0  \n",
      "186      0  \n",
      "324      0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "data = pd.read_csv(\"Youtube01-Psy.csv\")\n",
    "print(data.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               CONTENT  CLASS\n",
      "182                             OPPA GANGNAM STYLE!!!﻿      0\n",
      "14   please like :D https://premium.easypromosapp.c...      1\n",
      "57   Subscribe and like to me for more how to video...      1\n",
      "8      You should check my channel for Funny VIDEOS!!﻿      1\n",
      "12                https://twitter.com/GBphotographyGB﻿      1\n"
     ]
    }
   ],
   "source": [
    "data = data[[\"CONTENT\", \"CLASS\"]]\n",
    "print(data.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               CONTENT         CLASS\n",
      "93   Does anyone here use gift cards like Amazon, i...  Spam Comment\n",
      "134                              ❤️ ❤️ ❤️ ❤️ ❤️❤️❤️❤️﻿      Not Spam\n",
      "142  pls http://www10.vakinha.com.br/VaquinhaE.aspx...  Spam Comment\n",
      "1    Hey guys check out my new channel and our firs...  Spam Comment\n",
      "129  Like getting Gift cards..but hate spending the...  Spam Comment\n"
     ]
    }
   ],
   "source": [
    "data[\"CLASS\"] = data[\"CLASS\"].map({0: \"Not Spam\",\n",
    "                                   1: \"Spam Comment\"})\n",
    "print(data.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9857142857142858\n"
     ]
    }
   ],
   "source": [
    "x = np.array(data[\"CONTENT\"])\n",
    "y = np.array(data[\"CLASS\"])\n",
    "\n",
    "cv = CountVectorizer()\n",
    "x = cv.fit_transform(x)\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, \n",
    "                                                test_size=0.2, \n",
    "                                                random_state=42)\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(xtrain, ytrain)\n",
    "print(model.score(xtest, ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let’s test the model by giving spam and not spam comments as input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Spam Comment']\n"
     ]
    }
   ],
   "source": [
    "sample = \"Check this out: https://thecleverprogrammer.com/\" \n",
    "data = cv.transform([sample]).toarray()\n",
    "print(model.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Not Spam']\n"
     ]
    }
   ],
   "source": [
    "sample = \"Lack of information!\" \n",
    "data = cv.transform([sample]).toarray()\n",
    "print(model.predict(data)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
